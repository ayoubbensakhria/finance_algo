{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rautor rewriter.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "vTzy9dhmzpPG",
        "ZRTd98AbVVbD"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNQoz4EopFEQX+noL9TNKQD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayoubbensakhria/finance_algo/blob/master/Rautor_rewriter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Install required packages and do necessary imports\n"
      ],
      "metadata": {
        "id": "qZ6a0a2YvjHM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.0. Objectives\n",
        "* Build a **SOLID and EFFECTIVE** text generator/rewriter based on human and machine generated sequences\n",
        "* Process: simple: sentence > pilars and interstitial sequences > replace interstitial sequences and preserve pilars to keep the sentence sense intact  \n",
        "\n",
        "- **input**: **kw**: the effectiveness of marketing on boosting sales, **mode**:academic, **max_length**:2000, **variants**: 5, **media_placeholders**=True\n",
        "\n",
        "###1.0.1. Stages\n",
        "*Stage 1*:\n",
        "- Input text Pilars -> output original text intact when the same reference is specified.\n",
        "\n",
        "*Stage 2*\n",
        "- Input text Pilars -> output two concatenated texts when two references are specified\n",
        "\n",
        "*Stage 3*\n",
        "- Input text Pilars -> Output multiple concatenated texts with respect to the references specified at input.\n",
        "\n",
        "*Stage 4*\n",
        "- Pilar graph builder using LSTM model\n",
        "- Machine sequences builder (Semantic regression ML sentence generator)\n",
        "- Semantic classifier ML (to choose the most matching semantic sequence possible)\n",
        "\n",
        "*Stage 5*\n",
        "\n",
        "Fresh content generator:  \n",
        "\n",
        "* Download and learn fresh content\n",
        "* Generate optimized pilar graph\n",
        "* Generate high quality unique and fresh content"
      ],
      "metadata": {
        "id": "a8Z-1MVCm9pJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --user -U nltk"
      ],
      "metadata": {
        "id": "lfmrMsIhwBgl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df98938f-248a-48a5-8ac1-d5281138fa6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Collecting nltk\n",
            "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Collecting regex>=2021.8.3\n",
            "  Downloading regex-2022.6.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
            "\u001b[K     |████████████████████████████████| 749 kB 49.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.1.0)\n",
            "Installing collected packages: regex, nltk\n",
            "\u001b[33m  WARNING: The script nltk is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "Successfully installed nltk-3.7 regex-2022.6.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xN6H8uYnPr6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e16d38f-c6ab-4855-deb5-87d4b26e2c40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import json\n",
        "import time\n",
        "import random\n",
        "from google.colab import drive\n",
        "from lxml import html\n",
        "from lxml.html.clean import clean_html, Cleaner\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from pandas import json_normalize\n",
        "import re\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# file name\n",
        "filename = \"learn_content_export\"\n",
        "\n",
        "# first word \n",
        "FIRST = 'FST '\n",
        "# last word \n",
        "LAST = ' LST'"
      ],
      "metadata": {
        "id": "a72VUlNhvfsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1. Analyse a text\n",
        " \n",
        "* Get sentences\n",
        "* For each sentence\n",
        "  * if the sentence doesn't begin with a pilar create one\n",
        "  * if the sentence doesn't end with a pilar create one\n",
        "  * get pilars \n",
        "  * get the sequence (vector) after to the next pilar\n",
        "  * add pilars to the pilar collection (text)\n",
        "\n",
        "----\n",
        "### Result: \n",
        "\n",
        "Each beginning pilar has SEQ and ending pilar\n",
        "\n",
        "Database: \n",
        "PILAR1 - SEQ - PILAR2 - SEQ - PILAR3\n",
        "\n",
        "| Begin Pilar | SEQ_H | SEQ_M | End Pilar|\n",
        "|---|---|---|---|\n",
        "|PILAR 1| HUMAN SEQ LIST | MACHINE SEQ LIST | PILAR 2 | \n",
        "\n",
        "Vriables: \n",
        "\n",
        "* *b_pilar* : beginning pilar\n",
        "* *e_pilar*: end pilar \n",
        "* *h_seq*: human sequence\n",
        "* *m_seq*: machine-generated sequence\n"
      ],
      "metadata": {
        "id": "vTzy9dhmzpPG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Classes and Functions"
      ],
      "metadata": {
        "id": "-iL1vtScx5as"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2.1. classes"
      ],
      "metadata": {
        "id": "ZRTd98AbVVbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sequence (object):\n",
        "\n",
        "  def __init__(self, *args):\n",
        "\n",
        "    self.sequence = args[0]['sequence'] if args else ''\n",
        "    self.longReference = args[0]['longReference'] if args else 'web'\n",
        "    self.shortReference = args[0]['shortReference'] if args  else 'web'\n",
        "    self.verified = args[0]['verified'] if args else False\n",
        "\n",
        "  def to_json(self):\n",
        "    return {\n",
        "        'sequence': self.sequence,\n",
        "        'longReference': self.longReference,\n",
        "        'shortReference': self.shortReference,\n",
        "        'verified': self.verified,\n",
        "    }\n",
        "   \n",
        "\"\"\"\n",
        "input = json.loads('{\"sequence\": \"\", \"longReference\": \"web\", \"shortReference\": \"web\", \"verified\": false, \"isMachine\": false}')\n",
        "print(type(input))\n",
        "seq = Sequence(input)\n",
        "print(type(seq.isMachine))\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "V1nxrKOf4Ds5",
        "outputId": "7d35375d-30a2-47b5-917a-0f9db761ccd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ninput = json.loads(\\'{\"sequence\": \"\", \"longReference\": \"web\", \"shortReference\": \"web\", \"verified\": false, \"isMachine\": false}\\')\\nprint(type(input))\\nseq = Sequence(input)\\nprint(type(seq.isMachine))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Functions"
      ],
      "metadata": {
        "id": "bo-FJmhpzAo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pilars(text):\n",
        "  words = word_tokenize(text)\n",
        "  pilars = []\n",
        "  for pilar in nltk.pos_tag(words):\n",
        "    if pilar[1] in ['NN', 'NNS', 'NNP']:\n",
        "      pilars.append(pilar[0])\n",
        "  return pilars \n",
        "\n",
        "def is_pilar(word):\n",
        "  pilar = nltk.pos_tag(word_tokenize(word))\n",
        "  return pilar[0][1] in ['NN', 'NNS', 'NNP']\n",
        "\n",
        "def get_adjectives(text):\n",
        "  words = word_tokenize(text)\n",
        "  adjectives = []\n",
        "  for adj in nltk.pos_tag(words):\n",
        "    if adj[1] == 'JJ':\n",
        "      adjectives.append(adj[0])\n",
        "  return adjectives \n",
        "\n",
        "def get_sequence_between(s1, s2, text):\n",
        "  result = re.search('{s1}(.*){s2}'.format(s1=s1, s2=s2), text)\n",
        "  return result.group(1)\n",
        "\n",
        "def get_sequence_between(s1, s2, text):\n",
        "  result = re.search('{s1}(.*){s2}'.format(s1=s1, s2=s2), text)\n",
        "  return result.group(1)\n",
        "\n",
        "def get_iterstitial_seqs(pilars, text):\n",
        "  # TODO\n",
        "  # fix data loss problem\n",
        "  # fix one char '(' ')' seq problem\n",
        "  _text = text\n",
        "  for pilar in pilars:\n",
        "    _text = _text.replace(pilar, ',')\n",
        "  if _text and ',' in _text:\n",
        "    _results = _text.split(',')\n",
        "    _results.pop()\n",
        "    _results.pop(0)\n",
        "    return _results\n",
        "  else:\n",
        "    return []\n",
        "\n",
        "def get_suggestions(b_pilar, e_pilar, dataframe):\n",
        "  suggestions = []\n",
        "  if (b_pilar in dataframe['b_pilar'].values) and (e_pilar in dataframe['e_pilar'].values):\n",
        "    suggestions = dataframe.loc[(dataframe['b_pilar']==b_pilar) & (dataframe['e_pilar']==e_pilar)]['h_seq'] ## <- \n",
        "  return suggestions\n",
        "\n",
        "def get_suggestions_mono(b_pilar, dataframe):\n",
        "  suggestions = []\n",
        "  if (b_pilar in dataframe['b_pilar'].values):\n",
        "    for suggestion in dataframe.loc[(dataframe['b_pilar']==b_pilar)]['h_seq'].values: \n",
        "      suggestions.append(suggestion)\n",
        "  return suggestions\n",
        "\n",
        "def text_to_parts(text, longReference, shortReference, dataframe):\n",
        "  df = dataframe\n",
        "  sentences = sent_tokenize(text)\n",
        "  for sent in sentences:\n",
        "    sentence = sent.strip()\n",
        "    sentence_words = word_tokenize(sentence)\n",
        "    # if sentence is <3 words pass\n",
        "    if (len(sent)<3):\n",
        "      continue\n",
        "    # check pilars at the beginning and end\n",
        "    if not is_pilar(sentence_words[0]):\n",
        "      sentence = FIRST + sentence\n",
        "      # case 'pilar is not doing' \n",
        "    if sentence_words [-1] != '.' and not is_pilar(sentence_words[-1]):\n",
        "      sentence = sentence + LAST + '.'\n",
        "      # case 'pilar is not doing.' \n",
        "    if sentence_words [-1] == '.' and not is_pilar(sentence_words[-2]):\n",
        "      sentence = sentence.replace('.', LAST) + '.'\n",
        "\n",
        "    # get pilars  \n",
        "    pilars = get_pilars(sentence)\n",
        "    # get sequences \n",
        "    sequences = get_iterstitial_seqs(pilars, sentence)\n",
        "    # assert n_pilars = n_sequence + 1\n",
        "    if(len(pilars) != len(sequences)+1):\n",
        "      continue\n",
        "\n",
        "    for i in range (len(pilars)-1):\n",
        "      # get string between two pilars\n",
        "      seq = sequences[i]\n",
        "      sequence = Sequence({\n",
        "        'sequence': seq,\n",
        "        'longReference': longReference,\n",
        "        'shortReference': shortReference,\n",
        "        'verified': True\n",
        "      })\n",
        "      if pilars[i] in df['b_pilar'].values:\n",
        "        index = df.loc[df['b_pilar']==pilars[i]].index.tolist()[0]\n",
        "        if df['e_pilar'].iloc[index] == pilars[i+1]:\n",
        "          # h_seq is a dict\n",
        "          # check duplicate\n",
        "          if (sequence.to_json() not in df['h_seq'].iloc[index]):\n",
        "            df['h_seq'].iloc[index].append(sequence.to_json())    \n",
        "        else:\n",
        "          row = {\n",
        "              'b_pilar': pilars[i],\n",
        "              'e_pilar': pilars[i+1],\n",
        "              'h_seq': [sequence.to_json()],\n",
        "              'm_seq': []\n",
        "          }\n",
        "          df = df.append(row, ignore_index = True)     \n",
        "      else:\n",
        "        row = {\n",
        "            'b_pilar': pilars[i],\n",
        "            'e_pilar': pilars[i+1],\n",
        "            'h_seq': [sequence.to_json()],\n",
        "            'm_seq': []\n",
        "        }\n",
        "        df = df.append(row, ignore_index = True)\n",
        "  return df"
      ],
      "metadata": {
        "id": "-UzhMxqVx8VL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe = pd.DataFrame(columns=['b_pilar', 'e_pilar', 'h_seq','m_seq'])\n",
        "df = pd.read_csv('https://storage.googleapis.com/dataset-uploader/bbc/bbc-text.csv')\n",
        "df_learn = df[:500]\n",
        "df_test = df[501:]\n",
        "print(len(df))"
      ],
      "metadata": {
        "id": "D4QvLdPLwftV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e060ba3b-6010-4246-a5c1-66d5b1ea9222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Compile "
      ],
      "metadata": {
        "id": "8ZRE6KrKyV9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for index, row in df_learn.iterrows():\n",
        "  dataframe = text_to_parts(row['text'], 'BBC News 2022 Long', 'BBC News', dataframe)\n",
        "dataframe.to_csv('/content/drive/MyDrive/data/{filename}.csv'.format(filename=filename))\n",
        "print(len(dataframe))"
      ],
      "metadata": {
        "id": "mxKnse4IyeBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "iiNXprm1LypP",
        "outputId": "d4a2a8cd-3ff4-46b9-8af9-27dec646a6ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   b_pilar  e_pilar                                              h_seq m_seq\n",
              "0       tv   future  [{'sequence': ' ', 'longReference': 'BBC News ...    []\n",
              "1   future    hands  [{'sequence': ' in the ', 'longReference': 'BB...    []\n",
              "2    hands  viewers  [{'sequence': ' of ', 'longReference': 'BBC Ne...    []\n",
              "3  viewers     home  [{'sequence': ' with ', 'longReference': 'BBC ...    []\n",
              "4     home  theatre  [{'sequence': ' ', 'longReference': 'BBC News ...    []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-afcd3c6e-8592-4fce-a786-7cb07ef193f4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>b_pilar</th>\n",
              "      <th>e_pilar</th>\n",
              "      <th>h_seq</th>\n",
              "      <th>m_seq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tv</td>\n",
              "      <td>future</td>\n",
              "      <td>[{'sequence': ' ', 'longReference': 'BBC News ...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>future</td>\n",
              "      <td>hands</td>\n",
              "      <td>[{'sequence': ' in the ', 'longReference': 'BB...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hands</td>\n",
              "      <td>viewers</td>\n",
              "      <td>[{'sequence': ' of ', 'longReference': 'BBC Ne...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>viewers</td>\n",
              "      <td>home</td>\n",
              "      <td>[{'sequence': ' with ', 'longReference': 'BBC ...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>home</td>\n",
              "      <td>theatre</td>\n",
              "      <td>[{'sequence': ' ', 'longReference': 'BBC News ...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-afcd3c6e-8592-4fce-a786-7cb07ef193f4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-afcd3c6e-8592-4fce-a786-7cb07ef193f4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-afcd3c6e-8592-4fce-a786-7cb07ef193f4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "suggestions = get_suggestions_mono('people', dataframe)\n",
        "for suggestion in suggestions:\n",
        "  print(suggestion[0]['sequence'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1A3AiIPzXrs",
        "outputId": "384b11ed-75b2-4da4-c9fd-533dc26ee821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " the \n",
            " the \n",
            " and if you would rather watch live \n",
            " they already have \n",
            " it said \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Rewrtiter class\n"
      ],
      "metadata": {
        "id": "NUI8TTL1ZduP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Rewriter(object):\n",
        "  def __init__(text, longReference, shortReference):\n",
        "    self.text = text \n",
        "  sentences = sent_tokenize(self.text)\n",
        "  for sent in sentences:\n",
        "    sentence = sent.strip()\n",
        "    sentence_words = word_tokenize(sentence)\n",
        "    # if sentence is <3 words pass\n",
        "    if (len(sent)<3):\n",
        "      continue\n",
        "    # check pilars at the beginning and end\n",
        "    if not is_pilar(sentence_words[0]):\n",
        "      sentence = FIRST + sentence\n",
        "      # case 'pilar is not doing' \n",
        "    if sentence_words [-1] != '.' and not is_pilar(sentence_words[-1]):\n",
        "      sentence = sentence + LAST + '.'\n",
        "      # case 'pilar is not doing.' \n",
        "    if sentence_words [-1] == '.' and not is_pilar(sentence_words[-2]):\n",
        "      sentence = sentence.replace('.', LAST) + '.'\n",
        "\n",
        "    # get pilars  \n",
        "    pilars = get_pilars(sentence)\n",
        "    for i in range(len(pilars)-1):\n",
        "\n",
        "      b_pilar = pilars[i]\n",
        "      e_pilar = pilars[i+1]\n",
        "\n",
        "      sequences = get_iterstitial_seqs(pilars, sentence)\n",
        "      suggestions = get_suggestions(b_pilar, e_pilar, dataframe)\n",
        "      ####################################\n",
        "      # choose the longest (experimental)#\n",
        "      ####################################\n",
        "      sequence_toreplace = '{b_pilar} {sequence} {e_pilar}'.format(b_pilar=b_pilar, sequence=sequences[i], e_pilar=e_pilar)\n",
        "      new_sequence = '<span style=\"color: green\">{b_pilar} {sequence} {e_pilar}</span>'.format(b_pilar=b_pilar, sequence=suggestions[0], e_pilar=e_pilar)\n",
        "      \n",
        "      if suggestions:\n",
        "        sentence.replace(sequence_toreplace, new_sequence)\n"
      ],
      "metadata": {
        "id": "9NYGOwPxZhZU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "240f0996-4b54-49be-f0a0-5d4f119bcc14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9f72147ffcb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mRewriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlongReference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshortReference\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-9f72147ffcb7>\u001b[0m in \u001b[0;36mRewriter\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlongReference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshortReference\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sent_tokenize' is not defined"
          ]
        }
      ]
    }
  ]
}